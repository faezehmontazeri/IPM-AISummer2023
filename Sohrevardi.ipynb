{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/faezehmontazeri/IPM-AISummer2023/blob/main/Sohrevardi.ipynb",
      "authorship_tag": "ABX9TyNkOS0N/PLgP0XKc1dng4RM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faezehmontazeri/IPM-AISummer2023/blob/main/Sohrevardi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0trJmd6DjqBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e74540b1-0ff2-4041-b133-dc962885ff1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.13.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FP5258xjs-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07683a5-9112-48fd-8654-9a53e0611cdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cityscapesscripts"
      ],
      "metadata": {
        "id": "jB5sUL-Hq7kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cityscapesscripts[gui]"
      ],
      "metadata": {
        "id": "YeTWiB9HrTnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from __future__ import print_function, absolute_import, division, unicode_literals\n",
        "\n",
        "#import appdirs\n",
        "#import argparse\n",
        "#import getpass\n",
        "#import hashlib\n",
        "#import json\n",
        "#import os\n",
        "#import requests\n",
        "#import shutil\n",
        "#import stat\n",
        "\n",
        "#from builtins import input\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "#import tensorflow.contrib.eager as tfe\n",
        "\n",
        "#Eager execution is enabled by default in version 2.x You can check that by using tf.executing_eagerly()\n",
        "#It should return True.\n",
        "#If you are having version less then 2.0 then it can be enabled by using tf.enable_eager_execution()\n",
        "tf.executing_eagerly()\n",
        "#Eager enabled by default in tf2, you do can disable it as below\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "#!wget https://www.cityscapes-dataset.com/file-handling/?packageID=1\n",
        "file_id = '1-7pEZa3O5UTDjH3L6F4ZZBjxMnRgpwEL'\n",
        "url = 'https://drive.google.com/uc?id={}'.format(file_id)\n",
        "\n",
        "#!wget 'https://drive.google.com/open?id=1-7pEZa3O5UTDjH3L6F4ZZBjxMnRgpwEL&authuser=0'\n",
        "#'https://drive.google.com/file/d/1-7pEZa3O5UTDjH3L6F4ZZBjxMnRgpwEL'\n",
        "#https://doc-0g-4g-docs.googleusercontent.com/docs/securesc/rgc31q317spmabsa7dm8q0te1a943j7q/ph2rh8qrql13hoadj9jsvupvpp1ro7av/1694785575000/13870146594497830143/10510790426494910345Z/1-7pEZa3O5UTDjH3L6F4ZZBjxMnRgpwEL?e=download&uuid=c34f927e-e26e-42fb-bb89-20b985ad2b0e&nonce=va8235fjkja3u&user=10510790426494910345Z&hash=ohpdppm05n9t0ai81rknh8med4q2tupl\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n"
      ],
      "metadata": {
        "id": "K9IgPidA0JJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "url = 'gdrive/MyDrive/ColabNotebooks/gtFine_trainvaltest.zip'\n",
        "!unzip 'gdrive/MyDrive/ColabNotebooks/gtFine_trainvaltest.zip'\n",
        "#gtFine_trainvaltest.zip"
      ],
      "metadata": {
        "id": "lIG5RXYG2Tjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTBSvHcSLBzc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCou80mnLLPV"
      },
      "outputs": [],
      "source": [
        "ds = tfds.load('cityscapes', split='train', shuffle_files=True)\n",
        "assert isinstance(ds, tf.data.Dataset)\n",
        "print(ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions to Read Image and Split Them\n",
        "def _read_to_tensor(fname, output_height=256, output_width=512, normalize_data=False):\n",
        "    '''Original images are 256 x 512 x 3. Left half is original image, right is semantic seg'''\n",
        "    img_strings = tf.read_file(fname)\n",
        "    imgs_decoded = tf.image.decode_jpeg(img_strings)\n",
        "    output = tf.image.resize_images(imgs_decoded, [output_height, output_width])\n",
        "    if normalize_data:\n",
        "        output = (output - 128) / 128\n",
        "    return output\n",
        "\n",
        "def _get_left_img_half(inp, width=256):\n",
        "    return inp[:, :width, :]\n",
        "\n",
        "def _get_right_img_half(inp, width=256):\n",
        "    return inp[:, width:, :]"
      ],
      "metadata": {
        "id": "9aQNzdSj-Zer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get List of Files and Apply Functions Above to Create Dataset\n",
        "#img_dir = '../input/cityscapes_data/cityscapes_data/train'\n",
        "img_dir = 'https://drive.google.com/file/d/1-7pEZa3O5UTDjH3L6F4ZZBjxMnRgpwEL/view?usp=sharing'\n",
        "file_list = os.listdir(img_dir)\n",
        "img_paths = [os.path.join(img_dir, fname) for fname in file_list]\n",
        "\n",
        "# Start with a dataset of directory names.\n",
        "output_height = 256\n",
        "output_width = 256\n",
        "my_data = tf.data.Dataset.from_tensor_slices(img_paths)\n",
        "img_tensors = my_data.map(_read_to_tensor)\n",
        "left_imgs = img_tensors.map(_get_left_img_half)\n",
        "right_imgs = img_tensors.map(_get_right_img_half)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "56uG75g9-wMU",
        "outputId": "349a18a8-cdde-47cd-f10f-f4b9014279a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c7362d8015b8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#img_dir = '../input/cityscapes_data/cityscapes_data/train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://drive.google.com/file/d/1-7pEZa3O5UTDjH3L6F4ZZBjxMnRgpwEL/view?usp=sharing'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mimg_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://drive.google.com/file/d/1-7pEZa3O5UTDjH3L6F4ZZBjxMnRgpwEL/view?usp=sharing'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple Demo That The Images Have Been Read\n",
        "\n",
        "#left_batches = tfe.Iterator(left_imgs)  # outside of TF Eager, we would use make_one_shot_iterator\n",
        "left_batches = tf.keras.preprocessing.image.Iterator(left_imgs)\n",
        "#right_batches = tfe.Iterator(right_imgs)\n",
        "right_batches = tf.keras.preprocessing.image.Iterator(right_imgs)\n",
        "n_images_to_show = 5\n",
        "\n",
        "for i in range(n_images_to_show):\n",
        "    left_img = left_batches.next().numpy().astype(np.uint8)\n",
        "    right_img = right_batches.next().numpy().astype(np.uint8)\n",
        "    fig = plt.figure()\n",
        "    fig.add_subplot(1,2,1)\n",
        "    plt.imshow(left_img)\n",
        "    fig.add_subplot(1,2,2)\n",
        "    plt.imshow(right_img)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "K_BFQZAP_MDR",
        "outputId": "832b3883-db21-4dec-d73f-a1e79275bbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4bc59a7ae7c8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#tf.keras.preprocessing.image.Iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#left_batches = tfe.Iterator(left_imgs)  # outside of TF Eager, we would use make_one_shot_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mleft_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#right_batches = tfe.Iterator(right_imgs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mright_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'left_imgs' is not defined"
          ]
        }
      ]
    }
  ]
}