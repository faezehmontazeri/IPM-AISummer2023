{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faezehmontazeri/IPM-AISummer2023/blob/main/CFPNet_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "__all__ = [\"CFPNet\"]\n",
        "\n",
        "class DeConv(nn.Module):\n",
        "    def __init__(self, nIn, nOut, kSize, stride, padding, output_padding, dilation=(1, 1), groups=1, bn_acti=False, bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bn_acti = bn_acti\n",
        "\n",
        "        self.conv = nn.ConvTranspose2d(nIn, nOut, kernel_size=kSize,\n",
        "                              stride=stride, padding=padding, output_padding=output_padding,\n",
        "                              dilation=dilation, groups=groups, bias=bias)\n",
        "\n",
        "        if self.bn_acti:\n",
        "            self.bn_prelu = BNPReLU(nOut)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.conv(input)\n",
        "\n",
        "        if self.bn_acti:\n",
        "            output = self.bn_prelu(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "class Conv(nn.Module):\n",
        "    def __init__(self, nIn, nOut, kSize, stride, padding, dilation=(1, 1), groups=1, bn_acti=False, bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bn_acti = bn_acti\n",
        "\n",
        "        self.conv = nn.Conv2d(nIn, nOut, kernel_size=kSize,\n",
        "                              stride=stride, padding=padding,\n",
        "                              dilation=dilation, groups=groups, bias=bias)\n",
        "\n",
        "        if self.bn_acti:\n",
        "            self.bn_prelu = BNPReLU(nOut)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.conv(input)\n",
        "\n",
        "        if self.bn_acti:\n",
        "            output = self.bn_prelu(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class BNPReLU(nn.Module):\n",
        "    def __init__(self, nIn):\n",
        "        super().__init__()\n",
        "        self.bn = nn.BatchNorm2d(nIn, eps=1e-3)\n",
        "        self.acti = nn.PReLU(nIn)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.bn(input)\n",
        "        output = self.acti(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "class CFPModule(nn.Module):\n",
        "    def __init__(self, nIn, d=1, KSize=3,dkSize=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bn_relu_1 = BNPReLU(nIn)\n",
        "        self.bn_relu_2 = BNPReLU(nIn)\n",
        "        self.conv1x1_1 = Conv(nIn, nIn // 4, KSize, 1, padding=1, bn_acti=True)\n",
        "\n",
        "        self.dconv3x1_4_1 = Conv(nIn // 4, nIn // 16, (dkSize, 1), 1,\n",
        "                              padding=(1*d+1, 0), dilation=(d+1,1), groups = nIn //16, bn_acti=True)\n",
        "        self.dconv1x3_4_1 = Conv(nIn // 16, nIn // 16, (1, dkSize), 1,\n",
        "                              padding=(0, 1*d+1), dilation=(1,d+1), groups = nIn //16, bn_acti=True)\n",
        "\n",
        "        self.dconv3x1_4_2 = Conv(nIn // 16, nIn // 16, (dkSize, 1), 1,\n",
        "                              padding=(1*d+1, 0), dilation=(d+1,1),groups = nIn //16, bn_acti=True)\n",
        "        self.dconv1x3_4_2 = Conv(nIn // 16, nIn // 16, (1, dkSize), 1,\n",
        "                              padding=(0, 1*d+1), dilation=(1,d+1),groups = nIn //16, bn_acti=True)\n",
        "\n",
        "        self.dconv3x1_4_3 = Conv(nIn // 16, nIn // 8, (dkSize, 1), 1,\n",
        "                              padding=(1*d+1, 0), dilation=(d+1,1),groups = nIn //16, bn_acti=True)\n",
        "        self.dconv1x3_4_3 = Conv(nIn // 8, nIn // 8, (1, dkSize), 1,\n",
        "                              padding=(0, 1*d+1), dilation=(1,d+1),groups = nIn //8, bn_acti=True)\n",
        "\n",
        "        self.dconv3x1_1_1 = Conv(nIn // 4, nIn // 16, (dkSize, 1), 1,\n",
        "                              padding=(1, 0),groups = nIn //16, bn_acti=True)\n",
        "        self.dconv1x3_1_1 = Conv(nIn // 16, nIn // 16, (1, dkSize), 1,\n",
        "                              padding=(0, 1),groups = nIn //16, bn_acti=True)\n",
        "\n",
        "        self.dconv3x1_1_2 = Conv(nIn // 16, nIn // 16, (dkSize, 1), 1,\n",
        "                              padding=(1, 0),groups = nIn //16, bn_acti=True)\n",
        "        self.dconv1x3_1_2 = Conv(nIn // 16, nIn // 16, (1, dkSize), 1,\n",
        "                              padding=(0, 1),groups = nIn //16, bn_acti=True)\n",
        "\n",
        "        self.dconv3x1_1_3 = Conv(nIn // 16, nIn // 8, (dkSize, 1), 1,\n",
        "                              padding=(1, 0),groups = nIn //16, bn_acti=True)\n",
        "        self.dconv1x3_1_3 = Conv(nIn // 8, nIn // 8, (1, dkSize), 1,\n",
        "                              padding=(0, 1),groups = nIn //8, bn_acti=True)\n",
        "\n",
        "\n",
        "        self.dconv3x1_2_1 = Conv(nIn // 4, nIn // 16, (dkSize, 1), 1,\n",
        "                              padding=(int(d/4+1), 0), dilation=(int(d/4+1),1), groups = nIn //16, bn_acti=True)\n",
        "        self.dconv1x3_2_1 = Conv(nIn // 16, nIn // 16, (1, dkSize), 1,\n",
        "                              padding=(0, int(d/4+1)), dilation=(1,int(d/4+1)), groups = nIn //16, bn_acti=True)\n",
        "\n",
        "        self.dconv3x1_2_2 = Conv(nIn // 16, nIn // 16, (dkSize, 1), 1,\n",
        "                              padding=(int(d/4+1), 0), dilation=(int(d/4+1),1),groups = nIn //16, bn_acti=True)\n",
        "        self.dconv1x3_2_2 = Conv(nIn // 16, nIn // 16, (1, dkSize), 1,\n",
        "                              padding=(0, int(d/4+1)), dilation=(1,int(d/4+1)),groups = nIn //16, bn_acti=True)\n",
        "\n",
        "        self.dconv3x1_2_3 = Conv(nIn // 16, nIn // 8, (dkSize, 1), 1,\n",
        "                              padding=(int(d/4+1), 0), dilation=(int(d/4+1),1),groups = nIn //16, bn_acti=True)\n",
        "        self.dconv1x3_2_3 = Conv(nIn // 8, nIn // 8, (1, dkSize), 1,\n",
        "                              padding=(0, int(d/4+1)), dilation=(1,int(d/4+1)),groups = nIn //8, bn_acti=True)\n",
        "\n",
        "\n",
        "\n",
        "        self.dconv3x1_3_1 = Conv(nIn // 4, nIn // 16, (dkSize, 1), 1,\n",
        "                              padding=(int(d/2+1), 0), dilation=(int(d/2+1),1), groups = nIn //16, bn_acti=True)\n",
        "        self.dconv1x3_3_1 = Conv(nIn // 16, nIn // 16, (1, dkSize), 1,\n",
        "                              padding=(0, int(d/2+1)), dilation=(1,int(d/2+1)), groups = nIn //16, bn_acti=True)\n",
        "\n",
        "        self.dconv3x1_3_2 = Conv(nIn // 16, nIn // 16, (dkSize, 1), 1,\n",
        "                              padding=(int(d/2+1), 0), dilation=(int(d/2+1),1),groups = nIn //16, bn_acti=True)\n",
        "        self.dconv1x3_3_2 = Conv(nIn // 16, nIn // 16, (1, dkSize), 1,\n",
        "                              padding=(0, int(d/2+1)), dilation=(1,int(d/2+1)),groups = nIn //16, bn_acti=True)\n",
        "\n",
        "        self.dconv3x1_3_3 = Conv(nIn // 16, nIn // 8, (dkSize, 1), 1,\n",
        "                              padding=(int(d/2+1), 0), dilation=(int(d/2+1),1),groups = nIn //16, bn_acti=True)\n",
        "        self.dconv1x3_3_3 = Conv(nIn // 8, nIn // 8, (1, dkSize), 1,\n",
        "                              padding=(0, int(d/2+1)), dilation=(1,int(d/2+1)),groups = nIn //8, bn_acti=True)\n",
        "\n",
        "        self.conv1x1 = Conv(nIn, nIn, 1, 1, padding=0,bn_acti=False)\n",
        "\n",
        "    def forward(self, input):\n",
        "        inp = self.bn_relu_1(input)\n",
        "        inp = self.conv1x1_1(inp)\n",
        "\n",
        "        o1_1 = self.dconv3x1_1_1(inp)\n",
        "        o1_1 = self.dconv1x3_1_1(o1_1)\n",
        "        o1_2 = self.dconv3x1_1_2(o1_1)\n",
        "        o1_2 = self.dconv1x3_1_2(o1_2)\n",
        "        o1_3 = self.dconv3x1_1_3(o1_2)\n",
        "        o1_3 = self.dconv1x3_1_3(o1_3)\n",
        "\n",
        "        o2_1 = self.dconv3x1_2_1(inp)\n",
        "        o2_1 = self.dconv1x3_2_1(o2_1)\n",
        "        o2_2 = self.dconv3x1_2_2(o2_1)\n",
        "        o2_2 = self.dconv1x3_2_2(o2_2)\n",
        "        o2_3 = self.dconv3x1_2_3(o2_2)\n",
        "        o2_3 = self.dconv1x3_2_3(o2_3)\n",
        "\n",
        "        o3_1 = self.dconv3x1_3_1(inp)\n",
        "        o3_1 = self.dconv1x3_3_1(o3_1)\n",
        "        o3_2 = self.dconv3x1_3_2(o3_1)\n",
        "        o3_2 = self.dconv1x3_3_2(o3_2)\n",
        "        o3_3 = self.dconv3x1_3_3(o3_2)\n",
        "        o3_3 = self.dconv1x3_3_3(o3_3)\n",
        "\n",
        "\n",
        "        o4_1 = self.dconv3x1_4_1(inp)\n",
        "        o4_1 = self.dconv1x3_4_1(o4_1)\n",
        "        o4_2 = self.dconv3x1_4_2(o4_1)\n",
        "        o4_2 = self.dconv1x3_4_2(o4_2)\n",
        "        o4_3 = self.dconv3x1_4_3(o4_2)\n",
        "        o4_3 = self.dconv1x3_4_3(o4_3)\n",
        "\n",
        "\n",
        "        output_1 = torch.cat([o1_1,o1_2,o1_3], 1)\n",
        "        output_2 = torch.cat([o2_1,o2_2,o2_3], 1)\n",
        "        output_3 = torch.cat([o3_1,o3_2,o3_3], 1)\n",
        "        output_4 = torch.cat([o4_1,o4_2,o4_3], 1)\n",
        "\n",
        "        ad1 = output_1\n",
        "        ad2 = ad1 + output_2\n",
        "        ad3 = ad2 + output_3\n",
        "        ad4 = ad3 + output_4\n",
        "        output = torch.cat([ad1,ad2,ad3,ad4],1)\n",
        "        output = self.bn_relu_2(output)\n",
        "        output = self.conv1x1(output)\n",
        "\n",
        "        return output+input\n",
        "\n",
        "\n",
        "class DownSamplingBlock(nn.Module):\n",
        "    def __init__(self, nIn, nOut):\n",
        "        super().__init__()\n",
        "        self.nIn = nIn\n",
        "        self.nOut = nOut\n",
        "\n",
        "        if self.nIn < self.nOut:\n",
        "            nConv = nOut - nIn\n",
        "        else:\n",
        "            nConv = nOut\n",
        "\n",
        "        self.conv3x3 = Conv(nIn, nConv, kSize=3, stride=2, padding=1)\n",
        "        self.max_pool = nn.MaxPool2d(2, stride=2)\n",
        "        self.bn_prelu = BNPReLU(nOut)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.conv3x3(input)\n",
        "\n",
        "        if self.nIn < self.nOut:\n",
        "            max_pool = self.max_pool(input)\n",
        "            output = torch.cat([output, max_pool], 1)\n",
        "\n",
        "        output = self.bn_prelu(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class InputInjection(nn.Module):\n",
        "    def __init__(self, ratio):\n",
        "        super().__init__()\n",
        "        self.pool = nn.ModuleList()\n",
        "        for i in range(0, ratio):\n",
        "            self.pool.append(nn.AvgPool2d(3, stride=2, padding=1))\n",
        "\n",
        "    def forward(self, input):\n",
        "        for pool in self.pool:\n",
        "            input = pool(input)\n",
        "\n",
        "        return input\n",
        "\n",
        "\n",
        "class CFPNet(nn.Module):\n",
        "    def __init__(self, classes=11, block_1=2, block_2=6):\n",
        "        super().__init__()\n",
        "        self.init_conv = nn.Sequential(\n",
        "            Conv(3, 32, 3, 2, padding=1, bn_acti=True),\n",
        "            Conv(32, 32, 3, 1, padding=1, bn_acti=True),\n",
        "            Conv(32, 32, 3, 1, padding=1, bn_acti=True),\n",
        "        )\n",
        "\n",
        "        self.down_1 = InputInjection(1)  # down-sample the image 1 times\n",
        "        self.down_2 = InputInjection(2)  # down-sample the image 2 times\n",
        "        self.down_3 = InputInjection(3)  # down-sample the image 3 times\n",
        "\n",
        "        self.bn_prelu_1 = BNPReLU(32 + 3)\n",
        "        dilation_block_1 =[2,2]\n",
        "        # CFP Block 1\n",
        "        self.downsample_1 = DownSamplingBlock(32 + 3, 64)\n",
        "        self.CFP_Block_1 = nn.Sequential()\n",
        "        for i in range(0, block_1):\n",
        "            self.CFP_Block_1.add_module(\"CFP_Module_1_\" + str(i), CFPModule(64, d=dilation_block_1[i]))\n",
        "\n",
        "        self.bn_prelu_2 = BNPReLU(128 + 3)\n",
        "\n",
        "        # CFP Block 2\n",
        "        dilation_block_2 = [4,4,8,8,16,16] #camvid #cityscapes [4,4,8,8,16,16] # [4,8,16]\n",
        "        self.downsample_2 = DownSamplingBlock(128 + 3, 128)\n",
        "        self.CFP_Block_2 = nn.Sequential()\n",
        "        for i in range(0, block_2):\n",
        "            self.CFP_Block_2.add_module(\"CFP_Module_2_\" + str(i),\n",
        "                                        CFPModule(128, d=dilation_block_2[i]))\n",
        "        self.bn_prelu_3 = BNPReLU(256 + 3)\n",
        "\n",
        "        self.classifier = nn.Sequential(Conv(259, classes, 1, 1, padding=0))\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        output0 = self.init_conv(input)\n",
        "\n",
        "        down_1 = self.down_1(input)\n",
        "        down_2 = self.down_2(input)\n",
        "        down_3 = self.down_3(input)\n",
        "\n",
        "        output0_cat = self.bn_prelu_1(torch.cat([output0, down_1], 1))\n",
        "\n",
        "        # CFP Block 1\n",
        "        output1_0 = self.downsample_1(output0_cat)\n",
        "        output1 = self.CFP_Block_1(output1_0)\n",
        "        output1_cat = self.bn_prelu_2(torch.cat([output1, output1_0, down_2], 1))\n",
        "\n",
        "        # CFP Block 2\n",
        "        output2_0 = self.downsample_2(output1_cat)\n",
        "        output2 = self.CFP_Block_2(output2_0)\n",
        "        output2_cat = self.bn_prelu_3(torch.cat([output2, output2_0, down_3], 1))\n",
        "\n",
        "        out = self.classifier(output2_cat)\n",
        "        out = F.interpolate(out, input.size()[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "nLvx2U02V5Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def __init_weight(feature, conv_init, norm_layer, bn_eps, bn_momentum,\n",
        "                  **kwargs):\n",
        "    for name, m in feature.named_modules():\n",
        "        if isinstance(m, (nn.Conv2d, nn.Conv3d)):\n",
        "            conv_init(m.weight, **kwargs)\n",
        "        elif isinstance(m, norm_layer):\n",
        "            m.eps = bn_eps\n",
        "            m.momentum = bn_momentum\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "def init_weight(module_list, conv_init, norm_layer, bn_eps, bn_momentum,\n",
        "                **kwargs):\n",
        "    if isinstance(module_list, list):\n",
        "        for feature in module_list:\n",
        "            __init_weight(feature, conv_init, norm_layer, bn_eps, bn_momentum,\n",
        "                          **kwargs)\n",
        "    else:\n",
        "        __init_weight(module_list, conv_init, norm_layer, bn_eps, bn_momentum,\n",
        "                      **kwargs)\n",
        "\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "def netParams(model):\n",
        "    total_paramters = 0\n",
        "    for parameter in model.parameters():\n",
        "        i = len(parameter.size())\n",
        "        p = 1\n",
        "        for j in range(i):\n",
        "            p *= parameter.size(j)\n",
        "        total_paramters += p\n",
        "\n",
        "    return total_paramters"
      ],
      "metadata": {
        "id": "2ZyWaJh-dzqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timeit\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "from argparse import ArgumentParser"
      ],
      "metadata": {
        "id": "CoS_6N2fWWLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GLOBAL_SEED = 1234\n",
        "\n",
        "def val(args, val_loader, model):\n",
        "\n",
        "    # evaluation mode\n",
        "    model.eval()\n",
        "    total_batches = len(val_loader)\n",
        "\n",
        "    data_list = []\n",
        "    for i, (input, label, size, name) in enumerate(val_loader):\n",
        "        if args.cuda:\n",
        "            input = input.cuda()\n",
        "\n",
        "        input_var = torch.autograd.Variable(input,volatile=True)\n",
        "        label = torch.autograd.Variable(label, volatile=True)\n",
        "        output = model(input_var)\n",
        "        output = output.cpu().data[0].numpy()\n",
        "        gt = np.asarray(label[0].numpy(), dtype=np.uint8)\n",
        "        output = output.transpose(1, 2, 0)\n",
        "        output = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)\n",
        "        data_list.append([gt.flatten(), output.flatten()])"
      ],
      "metadata": {
        "id": "fLT_WmGyWez5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, train_loader, model, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "\n",
        "    total_batches = len(train_loader)\n",
        "    total_paramters = netParams(model)\n",
        "\n",
        "    for iteration, batch in enumerate(train_loader, 0):\n",
        "        args.per_iter = total_batches\n",
        "        args.max_iter = args.max_epochs * args.per_iter\n",
        "        args.cur_iter = epoch * args.per_iter + iteration\n",
        "        scheduler = WarmupPolyLR(optimizer, T_max=args.max_iter, cur_iter=args.cur_iter, warmup_factor=1.0 / 3,\n",
        "                                 warmup_iters=500, power=0.9)\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        start_time = time.time()\n",
        "        images, labels, _, _ = batch\n",
        "        if args.cuda:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "        images = torch.autograd.Variable(images)\n",
        "        labels = torch.autograd.Variable(labels.long())\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()  # set the grad to zero\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    average_epoch_loss_train = sum(epoch_loss) / len(epoch_loss)\n",
        "\n",
        "    return average_epoch_loss_train, lr"
      ],
      "metadata": {
        "id": "uaM8OWSzWtHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(args):\n",
        "    h, w = map(int, args.input_size.split(','))\n",
        "    input_size = (h, w)\n",
        "    print(\"input size:{}\".format(input_size))\n",
        "\n",
        "    # set the seed\n",
        "    setup_seed(GLOBAL_SEED)\n",
        "\n",
        "    cudnn.enabled = True\n",
        "    print(\"building network\")\n",
        "\n",
        "    # build the model and initialization\n",
        "    model = build_model(args.model, num_classes=args.classes)\n",
        "    init_weight(model, nn.init.kaiming_normal_,\n",
        "                nn.BatchNorm2d, 1e-3, 0.1,\n",
        "                mode='fan_in')\n",
        "\n",
        "    print(\"the number of parameters: %d ==> %.2f M\" % (total_paramters, (total_paramters / 1e6)))\n",
        "\n",
        "    # load data and data augmentation\n",
        "    datas, trainLoader, valLoader = build_dataset_train(args.dataset, input_size, args.batch_size, args.train_type)\n",
        "\n",
        "\n",
        "    weight = torch.from_numpy(datas['classWeights'])\n",
        "    # weight = torch.FloatTensor([3.03507951, 13.09507946, 4.54913664, 37.64795738, 35.78537802, 31.50943831,\n",
        "    #                     45.88744201, 39.936759, 6.05101481, 31.85754823, 16.92219283, 32.07766734, 47.35907214,\n",
        "    #                     11.34163794, 44.31105748, 45.81085476, 45.67260936, 48.3493813, 42.02189188])\n",
        "    print(\"data['classWeights']: \", weight)\n",
        "    if args.cuda:\n",
        "        weight = weight.cuda()\n",
        "\n",
        "\n",
        "    if  args.dataset == 'cityscapes':\n",
        "        min_kept = int(args.batch_size // len(args.gpus) * h * w // 32)\n",
        "        criteria = OhemCrossEntropy2dTensor(use_weight=True, ignore_label=ignore_label,\n",
        "                                          thresh=0.7, min_kept=min_kept)\n",
        "\n",
        "\n",
        "\n",
        "    args.savedir = (args.savedir + args.dataset + '/' + args.model + 'bs'\n",
        "                    + str(args.batch_size) + 'gpu' + str(args.gpu_nums) + \"_\" + str(args.train_type) + '/')\n",
        "\n",
        "    if not os.path.exists(args.savedir):\n",
        "        os.makedirs(args.savedir)\n",
        "\n",
        "    start_epoch = 0\n",
        "\n",
        "    # continue training\n",
        "    if args.resume:\n",
        "        if os.path.isfile(args.resume):\n",
        "            checkpoint = torch.load(args.resume)\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            model.load_state_dict(checkpoint['model'])\n",
        "            print(\"loaded checkpoint '{}' (epoch {})\".format(args.resume, checkpoint['epoch']))\n",
        "        else:\n",
        "            print(\"no checkpoint found at '{}'\".format(args.resume))\n",
        "\n",
        "    model.train()\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    logFileLoc = args.savedir + args.logFile\n",
        "    if os.path.isfile(logFileLoc):\n",
        "        logger = open(logFileLoc, 'a')\n",
        "    else:\n",
        "        logger = open(logFileLoc, 'w')\n",
        "        logger.write(\"Parameters: %s Seed: %s\" % (str(total_paramters), GLOBAL_SEED))\n",
        "        logger.write(\"\\n%s\\t\\t%s\\t%s\\t%s\" % ('Epoch', 'Loss(Tr)', 'mIOU (val)', 'lr'))\n",
        "    logger.flush()\n",
        "\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), args.lr, (0.9, 0.999), eps=1e-08, weight_decay=1e-4)\n",
        "    lossTr_list = []\n",
        "    epoches = []\n",
        "\n",
        "\n",
        "    print('beginning training')\n",
        "    for epoch in range(start_epoch, args.max_epochs):\n",
        "        lossTr, lr = train(args, trainLoader, model, criteria, optimizer, epoch)\n",
        "        lossTr_list.append(lossTr)\n",
        "\n",
        "        # validation\n",
        "        if epoch % 50 == 0 or epoch == (args.max_epochs - 1):\n",
        "            epoches.append(epoch)\n",
        "            mIOU_val, per_class_iu = val(args, valLoader, model)\n",
        "\n",
        "            # record train information\n",
        "            logger.write(\"\\n%d\\t\\t%.4f\\t\\t%.4f\\t\\t%.7f\" % (epoch, lossTr, lr))\n",
        "            logger.flush()\n",
        "            print(\"Epoch : \" + str(epoch) + ' Details')\n",
        "            print(\"Epoch No.: %d\\tTrain Loss = %.4f\\t mIOU(val) = %.4f\\t lr= %.6f\\n\" % (epoch, lossTr, lr))\n",
        "\n",
        "        else:\n",
        "            # record train information\n",
        "            logger.write(\"\\n%d\\t\\t%.4f\\t\\t\\t\\t%.7f\" % (epoch, lossTr, lr))\n",
        "            logger.flush()\n",
        "            print(\"Epoch : \" + str(epoch) + ' Details')\n",
        "            print(\"Epoch No.: %d\\tTrain Loss = %.4f\\t lr= %.6f\\n\" % (epoch, lossTr, lr))\n",
        "\n",
        "        # save the model\n",
        "        model_file_name = args.savedir + '/model_' + str(epoch + 1) + '.pth'\n",
        "        state = {\"epoch\": epoch + 1, \"model\": model.state_dict()}\n",
        "\n",
        "        if epoch >= args.max_epochs - 10:\n",
        "            torch.save(state, model_file_name)\n",
        "        elif not epoch % 50:\n",
        "            torch.save(state, model_file_name)\n",
        "\n",
        "    logger.close()"
      ],
      "metadata": {
        "id": "6_Pz6-NaW9ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    parser = ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--dataset', default=\"cityscapes\")\n",
        "    parser.add_argument('--input_size', type=str, default=\"512,1024\", help=\"input size of model\")\n",
        "    parser.add_argument('--lr', type=float, default=4.5e-4, help=\"initial learning rate\") #4.5e-4 for cityscapes\n",
        "    parser.add_argument('--batch_size', type=int, default=4, help=\"the batch size is set to 4 for 1 GPU\")\n",
        "    parser.add_argument('--savedir', default=\"./checkpoint/\", help=\"directory to save the model snapshot\")\n",
        "    parser.add_argument('--classes', type=int, default=19)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    ignore_label = 255\n",
        "\n",
        "    train_model(args)"
      ],
      "metadata": {
        "id": "A8ufX9csXNBn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}